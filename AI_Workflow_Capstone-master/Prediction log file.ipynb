{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction log file - creating and updating \n",
    "\n",
    "Logging is tied to a machine learning model to enable performance monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import joblib\n",
    "import uuid\n",
    "from collections import Counter,defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from termcolor import cprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the aavail data \n",
    "df = pd.read_csv(os.path.join(\".\",r\"data/aavail-target.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull out the target \n",
    "_y = df.pop('is_subscriber')   # drop (the column) and return the values from it\n",
    "y = np.zeros(_y.size)          # form a equal size array \"y\"\n",
    "y[_y==0] = 1                   # convert \"y\" as churn-data (\"=1\")\n",
    "\n",
    "## then drop the other columns as un-needed\n",
    "df.drop(columns=['customer_id','customer_name'],inplace=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,y,saved_model):\n",
    "    \"\"\"\n",
    "    function to train model\n",
    "    \"\"\" \n",
    "    df = pd.read_csv(os.path.join(\".\",r\"data/aavail-target.csv\"))\n",
    "    _y = df.pop('is_subscriber')\n",
    "    y = np.zeros(_y.size)\n",
    "    y[_y==0] = 1 \n",
    "    df.drop(columns=['customer_id','customer_name'],inplace=True)\n",
    "    # df.head()\n",
    "    X = df\n",
    "    \n",
    "    ## Perform a train-test split\n",
    "    rs = random_state = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                stratify=y, random_state=rs)\n",
    "    ## Specify parameters and model\n",
    "    ## for numeric\n",
    "    numeric_features = ['age', 'num_streams']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "                         ('imputer', SimpleImputer(strategy='mean')),\n",
    "                         ('scaler', StandardScaler())])\n",
    "\n",
    "    ## for categorical\n",
    "    categorical_features = ['country', 'subscriber_type']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "      ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "      ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    ## define \"preprocessor\" and passing it the specific values\n",
    "    preprocessor = ColumnTransformer(\n",
    "      transformers=[\n",
    "                   ('num', numeric_transformer, numeric_features),\n",
    "                   ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    ## fit model on training data\n",
    "    ## (i) svm\n",
    "    param_grid_svm = {\n",
    "                    'svm__C': [0.01,0.1,0.5,1.0,1.5,5.0,10.0],\n",
    "                    'svm__gamma': [0.001,0.01,0.1]\n",
    "    }\n",
    "    best_params = {}\n",
    "    pipe_svm = Pipeline(steps=[('pre', preprocessor),\n",
    "                                ('svm',SVC(kernel='rbf',\n",
    "                                           class_weight='balanced'))])\n",
    "    grid = GridSearchCV(pipe_svm, param_grid=param_grid_svm, cv=5, \n",
    "                       iid=False, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    print(\"-->\".join(pipe_svm.named_steps.keys()))\n",
    "\n",
    "    best_params = grid.best_params_\n",
    "    #print(\"best parameters:\", best_params)\n",
    "    print(\"f1_score\",round(f1_score(y_test, y_pred,average='binary'),3))\n",
    "\n",
    "    ## retrain using all data\n",
    "    grid.fit(X, y)\n",
    "    print(\"... saving model: {}\".format(saved_model))\n",
    "    joblib.dump(grid,saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_predict_log(y_pred,y_proba,query,runtime):\n",
    "    \"\"\"\n",
    "    update predict log file\n",
    "    \"\"\"\n",
    "    \n",
    "    ## name the logfile using something that cycles with date (day, month, year)    \n",
    "    today = date.today()\n",
    "    logfile = \"Prediction-{}-{}.log\".format(today.year, today.month)\n",
    "\n",
    "    ## write the data to a csv file    \n",
    "    header = ['unique_id','timestamp','y_pred','y_proba','x_shape','model_version','runtime']\n",
    "    write_header = False\n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "    with open(logfile,'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quotechar='|')\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        to_write = map(str,[uuid.uuid4(),time.time(),y_pred,y_proba,query.shape,MODEL_VERSION,runtime])\n",
    "        writer.writerow(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load():\n",
    "    \"\"\"\n",
    "    funtion to load model\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(saved_model):\n",
    "        raise Exception(\"Model '{}' cannot be found. Is the model trained?\".format(saved_model))\n",
    "    \n",
    "    model = joblib.load(saved_model)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,saved_model,verbose=True):\n",
    "    \"\"\"\n",
    "    generic function for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "    \n",
    "    ## ensure the model is loaded\n",
    "    model = joblib.load(saved_model)\n",
    "\n",
    "    ## input checks\n",
    "    if isinstance(query,list):\n",
    "        query = np.array([query])\n",
    "    if len(query.shape) == 1:\n",
    "        query = query.reshape(1, -1)\n",
    "    \n",
    "    ## make prediction and gather data for log entry\n",
    "    y_pred = model.predict(query)\n",
    "    y_proba = None\n",
    "    if 'predict_proba' in dir(model) and model.probability == True:\n",
    "        y_proba = model.predict_proba(query)\n",
    "    m, s = divmod(time.time()-time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "\n",
    "    ## update the log file\n",
    "    _update_predict_log(y_pred,y_proba,query,runtime)\n",
    "    \n",
    "    return(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
